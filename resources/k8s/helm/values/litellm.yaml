# Default values for litellm.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
replicaCount: 1
image:
  # Use "ghcr.io/berriai/litellm-database" for optimized image with database
  repository: ghcr.io/berriai/litellm-database
  pullPolicy: Always
  # Overrides the image tag whose default is the chart appVersion.
  # tag: "main-latest"
  tag: 'main-v1.61.20.rc'
imagePullSecrets: []
nameOverride: litellm
fullnameOverride: ''
serviceAccount:
  # Specifies whether a service account should be created
  create: false
  # Automatically mount a ServiceAccount's API credentials?
  automount: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: litellm
podAnnotations: {}
podLabels: {}
# At the time of writing, the litellm docker image requires write access to the
#  filesystem on startup so that prisma can install some dependencies.
podSecurityContext: {}
securityContext: {}
# capabilities:
#   drop:
#     - ALL
# readOnlyRootFilesystem: false
# runAsNonRoot: true
# runAsUser: 1000
# A list of Kubernetes Secret objects that will be exported to the LiteLLM proxy
#  pod as environment variables.  These secrets can then be referenced in the
#  configuration file (or "litellm" ConfigMap) with `os.environ/<Env Var Name>`
environmentSecrets:
  - litellm-env-secret
# A list of Kubernetes ConfigMap objects that will be exported to the LiteLLM proxy
#  pod as environment variables.  The ConfigMap kv-pairs can then be referenced in the
#  configuration file (or "litellm" ConfigMap) with `os.environ/<Env Var Name>`
environmentConfigMaps: []
# - litellm-env-configmap
service:
  type: ClusterIP
  port: 4000
ingress:
  enabled: true
  className: nginx
  annotations:
    kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: litellm.tqtensor.com
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls:
    - secretName: litellm-tls-secret
      hosts:
        - litellm.tqtensor.com
masterkey: changeme
# The elements within proxy_config are rendered as config.yaml for the proxy
#  Examples: https://github.com/BerriAI/litellm/tree/main/litellm/proxy/example_config_yaml
#  Reference: https://docs.litellm.ai/docs/proxy/configs
proxy_config:
  model_list:
    # At least one model must exist for the proxy to start.
    - model_name: google/gemini-pro-1.5
      litellm_params:
        model: vertex_ai/gemini-1.5-pro-002
        vertex_project: gen-lang-client-0608717027
        vertex_location: europe-west4
    - model_name: google/gemini-flash-1.5
      litellm_params:
        model: vertex_ai/gemini-1.5-flash-002
        vertex_project: gen-lang-client-0608717027
        vertex_location: europe-west4
    - model_name: google/gemini-pro-2.0
      litellm_params:
        model: vertex_ai/gemini-2.0-pro-exp-02-05
        vertex_project: gen-lang-client-0608717027
        vertex_location: us-central1
    - model_name: google/gemini-flash-2.0
      litellm_params:
        model: vertex_ai/gemini-2.0-flash-001
        vertex_project: gen-lang-client-0608717027
        vertex_location: us-central1
    - model_name: google/gemini-2.0-flash-thinking
      litellm_params:
        model: vertex_ai/gemini-2.0-flash-thinking-exp-01-21
        vertex_project: gen-lang-client-0608717027
        vertex_location: us-central1
    - model_name: google/multilingual-embedding
      litellm_params:
        model: vertex_ai/text-multilingual-embedding-002
        vertex_project: gen-lang-client-0608717027
        vertex_location: us-central1
    - model_name: bedrock/claude-3.7-sonnet
      litellm_params:
        model: bedrock/us.anthropic.claude-3-7-sonnet-20250219-v1:0
        aws_access_key_id: os.environ/BEDROCK_AWS_ACCESS_KEY_ID
        aws_secret_access_key: os.environ/BEDROCK_AWS_SECRET_ACCESS_KEY
        aws_region_name: us-east-1
    - model_name: bedrock/nova-lite-v1
      litellm_params:
        model: bedrock/converse/us.amazon.nova-lite-v1:0
        aws_access_key_id: os.environ/BEDROCK_AWS_ACCESS_KEY_ID
        aws_secret_access_key: os.environ/BEDROCK_AWS_SECRET_ACCESS_KEY
        aws_region_name: us-east-1
    - model_name: bedrock/nova-pro-v1
      litellm_params:
        model: bedrock/converse/us.amazon.nova-pro-v1:0
        aws_access_key_id: os.environ/BEDROCK_AWS_ACCESS_KEY_ID
        aws_secret_access_key: os.environ/BEDROCK_AWS_SECRET_ACCESS_KEY
        aws_region_name: us-east-1
    - model_name: bedrock/deepseek-r1
      litellm_params:
        model: bedrock/converse/us.deepseek.r1-v1:0
        aws_access_key_id: os.environ/BEDROCK_AWS_ACCESS_KEY_ID
        aws_secret_access_key: os.environ/BEDROCK_AWS_SECRET_ACCESS_KEY
        aws_region_name: us-west-2
    - model_name: azure/o3-mini
      litellm_params:
        model: azure/o3-mini
        api_base: os.environ/AZURE_API_BASE
        api_key: os.environ/AZURE_API_KEY
        api_version: 2024-12-01-preview
  general_settings:
    master_key: os.environ/PROXY_MASTER_KEY
  litellm_settings:
    drop_params: true
resources: {}
# We usually recommend not to specify default resources and to leave this as a conscious
# choice for the user. This also increases chances charts run on environments with little
# resources, such as Minikube. If you do want to specify resources, uncomment the following
# lines, adjust them as necessary, and remove the curly braces after 'resources:'.
# limits:
#   cpu: 100m
#   memory: 128Mi
# requests:
#   cpu: 100m
#   memory: 128Mi
autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80
# Additional volumes on the output Deployment definition.
volumes: []
# - name: foo
#   secret:
#     secretName: mysecret
#     optional: false
# Additional volumeMounts on the output Deployment definition.
volumeMounts: []
# - name: foo
#   mountPath: "/etc/foo"
#   readOnly: true
nodeSelector: {}
tolerations: []
affinity: {}
db:
  # Use an existing postgres server/cluster
  useExisting: true
  # How to connect to the existing postgres server/cluster
  endpoint: localhost
  database: litellm
  url: postgresql://$(DATABASE_USERNAME):$(DATABASE_PASSWORD)@$(DATABASE_HOST)/$(DATABASE_NAME)
  secret:
    name: litellm-postgres-secret
    usernameKey: username
    passwordKey: password
  # Use the Stackgres Helm chart to deploy an instance of a Stackgres cluster.
  #  The Stackgres Operator must already be installed within the target
  #  Kubernetes cluster.
  # TODO: Stackgres deployment currently unsupported
  useStackgresOperator: false
  # Use the Postgres Helm chart to create a single node, stand alone postgres
  #  instance.  See the "postgresql" top level key for additional configuration.
  deployStandalone: false
# Settings for Bitnami postgresql chart (if db.deployStandalone is true, ignored
#  otherwise)
postgresql:
  architecture: standalone
  auth:
    username: litellm
    database: litellm
    # You should override these on the helm command line with
    #  `--set postgresql.auth.postgres-password=<some good password>,postgresql.auth.password=<some good password>`
    password: HQJGdZgigJe05Mmt
    postgres-password: HQJGdZgigJe05Mmt
    # A secret is created by this chart (litellm-helm) with the credentials that
    #  the new Postgres instance should use.
    # existingSecret: ""
    # secretKeys:
    #   userPasswordKey: password
# requires cache: true in config file
# either enable this or pass a secret for REDIS_HOST, REDIS_PORT, REDIS_PASSWORD or REDIS_URL
# with cache: true to use existing redis instance
redis:
  enabled: true
  architecture: standalone
# Prisma migration job settings
migrationJob:
  # Enable or disable the schema migration Job
  enabled: true
  # Number of retries for the Job in case of failure
  retries: 3
  # Backoff limit for Job restarts
  backoffLimit: 4
  # Skip schema migrations for specific environments. When True, the job will exit with code 0.
  disableSchemaUpdate: false
  annotations: {}
# Additional environment variables to be added to the deployment
envVars: {}
# USE_DDTRACE: "true"
